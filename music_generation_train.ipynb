{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Generation Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2SqGIKKAGOC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37368,
     "status": "ok",
     "timestamp": 1630212968237,
     "user": {
      "displayName": "Avijit Pyne",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzmTwu1FeDPJgYdb_tFJWV-rBdyFY7y7iA-QqC1Q=s64",
      "userId": "10566366986206370977"
     },
     "user_tz": -330
    },
    "id": "euZoNj4raOLv",
    "outputId": "6d013df5-c06c-4a58-fec2-b300a5328ee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zeu80T0YaPGT"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/Music_Generation/input.txt','rb') as f:\n",
    "      input_text = f.read()\n",
    "input_text=str(input_text,'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1630143486014,
     "user": {
      "displayName": "Avijit Pyne",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzmTwu1FeDPJgYdb_tFJWV-rBdyFY7y7iA-QqC1Q=s64",
      "userId": "10566366986206370977"
     },
     "user_tz": -330
    },
    "id": "LIm6agC7eWuN",
    "outputId": "45bc76a6-cd55-452c-9bcf-5a7e75ba4fff"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'X: 1\\nT:A and D\\n% Nottingham Music Database\\nS:EF\\nY:AB\\nM:4/4\\nK:A\\nM:6/8\\nP:A\\nf|\"A\"ecc c2f|\"A\"ecc c2f|\"A\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text [:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting each and every charecter into a integer and create a dictionary of it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqW5Mn4HiIlz"
   },
   "outputs": [],
   "source": [
    "def generate_keys(text):\n",
    "    ## charecter to index dictionary  \n",
    "    char_to_idx = {ch:idx for idx,ch in enumerate(sorted(list(set(text))))}\n",
    "\n",
    "    ## Index to character dicrionary\n",
    "    idx_to_char = {idx:ch for ch,idx in char_to_idx.items()}\n",
    "\n",
    "    print(\"len of the  char_to_idx \",len(char_to_idx))\n",
    "    print(\"len of the  idx_to_char \",len(idx_to_char))\n",
    "    return char_to_idx,idx_to_char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1630143486022,
     "user": {
      "displayName": "Avijit Pyne",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzmTwu1FeDPJgYdb_tFJWV-rBdyFY7y7iA-QqC1Q=s64",
      "userId": "10566366986206370977"
     },
     "user_tz": -330
    },
    "id": "zLCUHyqtl0Vf",
    "outputId": "208bea5b-3c2b-4661-e2fa-611cc5242848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of the  char_to_idx  86\n",
      "len of the  idx_to_char  86\n"
     ]
    }
   ],
   "source": [
    "char_to_idx, idx_to_char = generate_keys(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RV2uFXgRnLYc"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/content/drive/MyDrive/Music_Generation/char_to_idx','w') as f:\n",
    "      json.dump(char_to_idx,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1630143486036,
     "user": {
      "displayName": "Avijit Pyne",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzmTwu1FeDPJgYdb_tFJWV-rBdyFY7y7iA-QqC1Q=s64",
      "userId": "10566366986206370977"
     },
     "user_tz": -330
    },
    "id": "yMo-rh-_tD7L",
    "outputId": "c4267ef0-b814-499d-c8b8-3ade6d387462"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129665"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zih4sOMCs1WR"
   },
   "source": [
    "### Generate Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Us8UJElqvxh"
   },
   "outputs": [],
   "source": [
    "def generate_batchs(T, vocab_size):  \n",
    "    length = T.shape[0] #129,665\n",
    "  ### 129665//16 = 8104 \n",
    "  ## number of batches = 8104 // 64 = 126\n",
    "  ## Now since it is a sequence data we will divide the 1st 8104 char in 126 batches, each batches will have these char in the 1st row.\n",
    "  ## similarly from 8105 - 16209th chars will be divided into 126 batches (each batch will have 64 sequence) and will be added at the 2nd row of each bayches\n",
    "  ## that is how at 8104 number interval we will tak char and divide them into batches and put them in respective rows of batches\n",
    "  ## So we will have the continuation of the sequence row wise for different batches  \n",
    "\n",
    "  #          Batch 1                  Batch 2               Batchs              batch 126\n",
    "  #   |0--------------------63| 64---------------127| ................ |8000------------8063|\n",
    "  #   |8104---------------8167| 8168------------8233| ................ |16104----------16167|\n",
    "  #                                         .\n",
    "  #                                         .\n",
    "  #                                         .\n",
    "  #   |121560-----------121624| .......................................|129601--------121665|\n",
    "\n",
    "  ## in this way we can keep the sequence information in the text data.\n",
    "    batch_char = int(length / batch_size); # 8,104\n",
    "    for start in range(0, 126*64,64):\n",
    "        X = np.zeros((batch_size, batch_sequence)) # (16,64)\n",
    "        Y = np.zeros((batch_size, batch_sequence, vocab_size)) #(16,64,86)\n",
    "\n",
    "        for batch_index in range(0,batch_size):\n",
    "            for col_index in range(0,batch_sequence):\n",
    "            X[batch_index, col_index] = T[batch_char * batch_index + start + col_index]\n",
    "            Y[batch_index, col_index, T[batch_char * batch_index + start + col_index+1]] = 1\n",
    "        yield X,Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1630143486046,
     "user": {
      "displayName": "Avijit Pyne",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzmTwu1FeDPJgYdb_tFJWV-rBdyFY7y7iA-QqC1Q=s64",
      "userId": "10566366986206370977"
     },
     "user_tz": -330
    },
    "id": "SAV_KWg3v6Ws",
    "outputId": "65c8a695-cf80-448e-bd31-0bb9e3b6693e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(char_to_idx)\n",
    "batch_size = 16\n",
    "seq_len = 64\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 2291,
     "status": "ok",
     "timestamp": 1630217165770,
     "user": {
      "displayName": "Avijit Pyne",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzmTwu1FeDPJgYdb_tFJWV-rBdyFY7y7iA-QqC1Q=s64",
      "userId": "10566366986206370977"
     },
     "user_tz": -330
    },
    "id": "IqGm2fO9A5JC"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding\n",
    "\n",
    "\n",
    "MODEL_DIR = '/content/drive/MyDrive/Music_Generation/model'\n",
    "\n",
    "def save_weights(epoch, model):\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    model.save_weights(os.path.join(MODEL_DIR, 'weights.{}.h5'.format(epoch)))\n",
    "\n",
    "def load_weights(epoch, model):\n",
    "    model.load_weights(os.path.join(MODEL_DIR, 'weights.{}.h5'.format(epoch)))\n",
    "\n",
    "def build_model(batch_size, seq_len, vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 512, batch_input_shape=(batch_size, seq_len)))\n",
    "    for i in range(3):\n",
    "        model.add(LSTM(256, return_sequences=True, stateful=True))\n",
    "        model.add(Dropout(0.2))\n",
    "    ## Using TimeDistributed Dense Layer for each return sequences\n",
    "    model.add(TimeDistributed(Dense(vocab_size))) \n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKCrgbc7BSK0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def train(text, epochs=100, save_freq=10):\n",
    "\n",
    "    #model_architecture\n",
    "    model = build_model(batch_size, batch_sequence, vocab_size)\n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    #Train data generation\n",
    "    T = np.asarray([char_to_idx[c] for c in text], dtype=np.int32) #convert complete text into numerical indices\n",
    "\n",
    "    print(\"Length of text:\" + str(T.size)) #129,665\n",
    "\n",
    "    steps_per_epoch = (len(text) / batch_size - 1) / batch_sequence  \n",
    "\n",
    "    #log = TrainLogger('training_log.csv')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "        \n",
    "        losses, accs = [], []\n",
    "\n",
    "        for i, (X, Y) in enumerate(generate_batchs(T, vocab_size)):\n",
    "            \n",
    "            #print(X);\n",
    "\n",
    "            loss, acc = model.train_on_batch(X, Y)\n",
    "            \n",
    "            losses.append(loss)\n",
    "            accs.append(acc)\n",
    "\n",
    "        print('epoch {}: loss = {}, acc = {}'.format(epoch + 1, np.mean(loss), np.mean(acc)))\n",
    "        \n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            save_weights(epoch + 1, model)\n",
    "            print('Saved checkpoint to', 'weights.{}.h5'.format(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1205084,
     "status": "ok",
     "timestamp": 1630144693229,
     "user": {
      "displayName": "Avijit Pyne",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhzmTwu1FeDPJgYdb_tFJWV-rBdyFY7y7iA-QqC1Q=s64",
      "userId": "10566366986206370977"
     },
     "user_tz": -330
    },
    "id": "y68qFdoOCFQY",
    "outputId": "9ec7bc78-df6b-4a2e-837c-33c4d60c412f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (16, 64, 512)             44032     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (16, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (16, 64, 86)              22102     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (16, 64, 86)              0         \n",
      "=================================================================\n",
      "Total params: 1,904,214\n",
      "Trainable params: 1,904,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Length of text:129665\n",
      "\n",
      "Epoch 1/100\n",
      "epoch 1: loss = 2.7011942863464355, acc = 0.2734375\n",
      "\n",
      "Epoch 2/100\n",
      "epoch 2: loss = 2.0024373531341553, acc = 0.4248046875\n",
      "\n",
      "Epoch 3/100\n",
      "epoch 3: loss = 1.741467833518982, acc = 0.498046875\n",
      "\n",
      "Epoch 4/100\n",
      "epoch 4: loss = 1.5925806760787964, acc = 0.517578125\n",
      "\n",
      "Epoch 5/100\n",
      "epoch 5: loss = 1.4941389560699463, acc = 0.5546875\n",
      "\n",
      "Epoch 6/100\n",
      "epoch 6: loss = 1.4326871633529663, acc = 0.580078125\n",
      "\n",
      "Epoch 7/100\n",
      "epoch 7: loss = 1.4079864025115967, acc = 0.5751953125\n",
      "\n",
      "Epoch 8/100\n",
      "epoch 8: loss = 1.3506407737731934, acc = 0.5986328125\n",
      "\n",
      "Epoch 9/100\n",
      "epoch 9: loss = 1.3194119930267334, acc = 0.61328125\n",
      "\n",
      "Epoch 10/100\n",
      "epoch 10: loss = 1.2857179641723633, acc = 0.6123046875\n",
      "Saved checkpoint to weights.10.h5\n",
      "\n",
      "Epoch 11/100\n",
      "epoch 11: loss = 1.238192081451416, acc = 0.625\n",
      "\n",
      "Epoch 12/100\n",
      "epoch 12: loss = 1.211035966873169, acc = 0.619140625\n",
      "\n",
      "Epoch 13/100\n",
      "epoch 13: loss = 1.159069538116455, acc = 0.6513671875\n",
      "\n",
      "Epoch 14/100\n",
      "epoch 14: loss = 1.1182328462600708, acc = 0.6416015625\n",
      "\n",
      "Epoch 15/100\n",
      "epoch 15: loss = 1.113146185874939, acc = 0.6552734375\n",
      "\n",
      "Epoch 16/100\n",
      "epoch 16: loss = 1.0553525686264038, acc = 0.677734375\n",
      "\n",
      "Epoch 17/100\n",
      "epoch 17: loss = 1.0247124433517456, acc = 0.689453125\n",
      "\n",
      "Epoch 18/100\n",
      "epoch 18: loss = 1.016814947128296, acc = 0.6884765625\n",
      "\n",
      "Epoch 19/100\n",
      "epoch 19: loss = 0.9873977899551392, acc = 0.6962890625\n",
      "\n",
      "Epoch 20/100\n",
      "epoch 20: loss = 0.9685932397842407, acc = 0.6982421875\n",
      "Saved checkpoint to weights.20.h5\n",
      "\n",
      "Epoch 21/100\n",
      "epoch 21: loss = 0.9242898225784302, acc = 0.7119140625\n",
      "\n",
      "Epoch 22/100\n",
      "epoch 22: loss = 0.9064083695411682, acc = 0.7119140625\n",
      "\n",
      "Epoch 23/100\n",
      "epoch 23: loss = 0.8860988020896912, acc = 0.716796875\n",
      "\n",
      "Epoch 24/100\n",
      "epoch 24: loss = 0.8557679653167725, acc = 0.728515625\n",
      "\n",
      "Epoch 25/100\n",
      "epoch 25: loss = 0.8414531350135803, acc = 0.7392578125\n",
      "\n",
      "Epoch 26/100\n",
      "epoch 26: loss = 0.8225206136703491, acc = 0.734375\n",
      "\n",
      "Epoch 27/100\n",
      "epoch 27: loss = 0.7997196912765503, acc = 0.73828125\n",
      "\n",
      "Epoch 28/100\n",
      "epoch 28: loss = 0.7789614796638489, acc = 0.7646484375\n",
      "\n",
      "Epoch 29/100\n",
      "epoch 29: loss = 0.7611321210861206, acc = 0.7626953125\n",
      "\n",
      "Epoch 30/100\n",
      "epoch 30: loss = 0.7260193228721619, acc = 0.763671875\n",
      "Saved checkpoint to weights.30.h5\n",
      "\n",
      "Epoch 31/100\n",
      "epoch 31: loss = 0.7122833728790283, acc = 0.7705078125\n",
      "\n",
      "Epoch 32/100\n",
      "epoch 32: loss = 0.7145253419876099, acc = 0.7646484375\n",
      "\n",
      "Epoch 33/100\n",
      "epoch 33: loss = 0.6626716256141663, acc = 0.787109375\n",
      "\n",
      "Epoch 34/100\n",
      "epoch 34: loss = 0.6513315439224243, acc = 0.7841796875\n",
      "\n",
      "Epoch 35/100\n",
      "epoch 35: loss = 0.6450920104980469, acc = 0.798828125\n",
      "\n",
      "Epoch 36/100\n",
      "epoch 36: loss = 0.6378451585769653, acc = 0.7919921875\n",
      "\n",
      "Epoch 37/100\n",
      "epoch 37: loss = 0.62325519323349, acc = 0.7890625\n",
      "\n",
      "Epoch 38/100\n",
      "epoch 38: loss = 0.6393232345581055, acc = 0.79296875\n",
      "\n",
      "Epoch 39/100\n",
      "epoch 39: loss = 0.54360032081604, acc = 0.822265625\n",
      "\n",
      "Epoch 40/100\n",
      "epoch 40: loss = 0.5867937207221985, acc = 0.8173828125\n",
      "Saved checkpoint to weights.40.h5\n",
      "\n",
      "Epoch 41/100\n",
      "epoch 41: loss = 0.5572314262390137, acc = 0.8154296875\n",
      "\n",
      "Epoch 42/100\n",
      "epoch 42: loss = 0.5311474204063416, acc = 0.814453125\n",
      "\n",
      "Epoch 43/100\n",
      "epoch 43: loss = 0.48921307921409607, acc = 0.8310546875\n",
      "\n",
      "Epoch 44/100\n",
      "epoch 44: loss = 0.5231114625930786, acc = 0.830078125\n",
      "\n",
      "Epoch 45/100\n",
      "epoch 45: loss = 0.4994143843650818, acc = 0.8291015625\n",
      "\n",
      "Epoch 46/100\n",
      "epoch 46: loss = 0.4564560055732727, acc = 0.8515625\n",
      "\n",
      "Epoch 47/100\n",
      "epoch 47: loss = 0.4721132516860962, acc = 0.8544921875\n",
      "\n",
      "Epoch 48/100\n",
      "epoch 48: loss = 0.4657353162765503, acc = 0.8564453125\n",
      "\n",
      "Epoch 49/100\n",
      "epoch 49: loss = 0.44506213068962097, acc = 0.86328125\n",
      "\n",
      "Epoch 50/100\n",
      "epoch 50: loss = 0.46004411578178406, acc = 0.849609375\n",
      "Saved checkpoint to weights.50.h5\n",
      "\n",
      "Epoch 51/100\n",
      "epoch 51: loss = 0.4137033224105835, acc = 0.865234375\n",
      "\n",
      "Epoch 52/100\n",
      "epoch 52: loss = 0.44400984048843384, acc = 0.84765625\n",
      "\n",
      "Epoch 53/100\n",
      "epoch 53: loss = 0.3958962559700012, acc = 0.876953125\n",
      "\n",
      "Epoch 54/100\n",
      "epoch 54: loss = 0.41268739104270935, acc = 0.85546875\n",
      "\n",
      "Epoch 55/100\n",
      "epoch 55: loss = 0.3789374530315399, acc = 0.8720703125\n",
      "\n",
      "Epoch 56/100\n",
      "epoch 56: loss = 0.4085407853126526, acc = 0.865234375\n",
      "\n",
      "Epoch 57/100\n",
      "epoch 57: loss = 0.3776632249355316, acc = 0.880859375\n",
      "\n",
      "Epoch 58/100\n",
      "epoch 58: loss = 0.3712006211280823, acc = 0.8837890625\n",
      "\n",
      "Epoch 59/100\n",
      "epoch 59: loss = 0.3732529282569885, acc = 0.8837890625\n",
      "\n",
      "Epoch 60/100\n",
      "epoch 60: loss = 0.35765340924263, acc = 0.876953125\n",
      "Saved checkpoint to weights.60.h5\n",
      "\n",
      "Epoch 61/100\n",
      "epoch 61: loss = 0.3654521107673645, acc = 0.8876953125\n",
      "\n",
      "Epoch 62/100\n",
      "epoch 62: loss = 0.3349286913871765, acc = 0.8935546875\n",
      "\n",
      "Epoch 63/100\n",
      "epoch 63: loss = 0.3072788715362549, acc = 0.8984375\n",
      "\n",
      "Epoch 64/100\n",
      "epoch 64: loss = 0.3411882519721985, acc = 0.8896484375\n",
      "\n",
      "Epoch 65/100\n",
      "epoch 65: loss = 0.3350088596343994, acc = 0.8896484375\n",
      "\n",
      "Epoch 66/100\n",
      "epoch 66: loss = 0.3165018558502197, acc = 0.908203125\n",
      "\n",
      "Epoch 67/100\n",
      "epoch 67: loss = 0.3232888877391815, acc = 0.9013671875\n",
      "\n",
      "Epoch 68/100\n",
      "epoch 68: loss = 0.3365902304649353, acc = 0.8857421875\n",
      "\n",
      "Epoch 69/100\n",
      "epoch 69: loss = 0.3277640640735626, acc = 0.8876953125\n",
      "\n",
      "Epoch 70/100\n",
      "epoch 70: loss = 0.3247421681880951, acc = 0.8974609375\n",
      "Saved checkpoint to weights.70.h5\n",
      "\n",
      "Epoch 71/100\n",
      "epoch 71: loss = 0.2799142599105835, acc = 0.9111328125\n",
      "\n",
      "Epoch 72/100\n",
      "epoch 72: loss = 0.2800166606903076, acc = 0.900390625\n",
      "\n",
      "Epoch 73/100\n",
      "epoch 73: loss = 0.3115411400794983, acc = 0.8994140625\n",
      "\n",
      "Epoch 74/100\n",
      "epoch 74: loss = 0.2693531811237335, acc = 0.9208984375\n",
      "\n",
      "Epoch 75/100\n",
      "epoch 75: loss = 0.30706849694252014, acc = 0.8935546875\n",
      "\n",
      "Epoch 76/100\n",
      "epoch 76: loss = 0.28987348079681396, acc = 0.9072265625\n",
      "\n",
      "Epoch 77/100\n",
      "epoch 77: loss = 0.3176339566707611, acc = 0.896484375\n",
      "\n",
      "Epoch 78/100\n",
      "epoch 78: loss = 0.28120720386505127, acc = 0.90625\n",
      "\n",
      "Epoch 79/100\n",
      "epoch 79: loss = 0.2787090837955475, acc = 0.9111328125\n",
      "\n",
      "Epoch 80/100\n",
      "epoch 80: loss = 0.3003750145435333, acc = 0.890625\n",
      "Saved checkpoint to weights.80.h5\n",
      "\n",
      "Epoch 81/100\n",
      "epoch 81: loss = 0.2736038267612457, acc = 0.90625\n",
      "\n",
      "Epoch 82/100\n",
      "epoch 82: loss = 0.27047640085220337, acc = 0.91015625\n",
      "\n",
      "Epoch 83/100\n",
      "epoch 83: loss = 0.24500009417533875, acc = 0.91796875\n",
      "\n",
      "Epoch 84/100\n",
      "epoch 84: loss = 0.2676354646682739, acc = 0.9140625\n",
      "\n",
      "Epoch 85/100\n",
      "epoch 85: loss = 0.27684545516967773, acc = 0.9111328125\n",
      "\n",
      "Epoch 86/100\n",
      "epoch 86: loss = 0.2570558190345764, acc = 0.9130859375\n",
      "\n",
      "Epoch 87/100\n",
      "epoch 87: loss = 0.23252186179161072, acc = 0.91796875\n",
      "\n",
      "Epoch 88/100\n",
      "epoch 88: loss = 0.21222138404846191, acc = 0.92578125\n",
      "\n",
      "Epoch 89/100\n",
      "epoch 89: loss = 0.21169091761112213, acc = 0.9345703125\n",
      "\n",
      "Epoch 90/100\n",
      "epoch 90: loss = 0.22502174973487854, acc = 0.9306640625\n",
      "Saved checkpoint to weights.90.h5\n",
      "\n",
      "Epoch 91/100\n",
      "epoch 91: loss = 0.28326669335365295, acc = 0.908203125\n",
      "\n",
      "Epoch 92/100\n",
      "epoch 92: loss = 0.2214236557483673, acc = 0.9326171875\n",
      "\n",
      "Epoch 93/100\n",
      "epoch 93: loss = 0.24583634734153748, acc = 0.9248046875\n",
      "\n",
      "Epoch 94/100\n",
      "epoch 94: loss = 0.19463028013706207, acc = 0.9326171875\n",
      "\n",
      "Epoch 95/100\n",
      "epoch 95: loss = 0.2246793806552887, acc = 0.9228515625\n",
      "\n",
      "Epoch 96/100\n",
      "epoch 96: loss = 0.235568106174469, acc = 0.9248046875\n",
      "\n",
      "Epoch 97/100\n",
      "epoch 97: loss = 0.2802346348762512, acc = 0.9072265625\n",
      "\n",
      "Epoch 98/100\n",
      "epoch 98: loss = 0.22525431215763092, acc = 0.9228515625\n",
      "\n",
      "Epoch 99/100\n",
      "epoch 99: loss = 0.24666661024093628, acc = 0.9208984375\n",
      "\n",
      "Epoch 100/100\n",
      "epoch 100: loss = 0.22200991213321686, acc = 0.923828125\n",
      "Saved checkpoint to weights.100.h5\n"
     ]
    }
   ],
   "source": [
    "train(input_text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP4xr09IA8dGbjVVXWlcGrY",
   "collapsed_sections": [],
   "mount_file_id": "13NKYFHRrE-CKgVWMWC7sxr32MjmA-woI",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
